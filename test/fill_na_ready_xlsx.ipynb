{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_excel(path)\n",
    "    title = df.iloc[3]['Unnamed: 0']\n",
    "    df = df.drop([2, 3])\n",
    "    data_groups = {}\n",
    "    current_group = df.iloc[0].values[0]\n",
    "\n",
    "    for index, value in zip(df.iloc[0].index, df.iloc[0].values):\n",
    "        if (pd.isna(value)):\n",
    "            data_groups[current_group].append(index)\n",
    "        else:\n",
    "            current_group = value\n",
    "            data_groups[current_group] = [index]\n",
    "\n",
    "    data_dfs = []\n",
    "    index = pd.to_datetime(df['Unnamed: 0'][2:-3], format='mixed')\n",
    "\n",
    "    for group, cols in zip(list(data_groups.keys())[1:], list(data_groups.values())[1:]):\n",
    "        data_df = df[cols].copy()\n",
    "        data_df.columns = data_df.iloc[1].values\n",
    "        data_df = data_df.drop([0, 1])[:-3]\n",
    "        data_df = data_df.set_index(index)\n",
    "        data_df.index = pd.to_datetime(data_df.index)\n",
    "        data_df.index.names = ['timestamp']\n",
    "        data_dfs.append((group, data_df))\n",
    "    \n",
    "    return title, data_groups, data_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/Svodniy_otchet_po_chasam_intensivnost+skorost_01_01_2024_31_12_2024.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "title, data_groups,data_dfs = load_data(\n",
    "    '../data/Svodniy_otchet_po_chasam_intensivnost+skorost_01_01_2024_31_12_2024.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2024-01-01 00:59:59', '2024-01-01 01:59:59',\n",
       "               '2024-01-01 02:59:59', '2024-01-01 03:59:59',\n",
       "               '2024-01-01 04:59:59', '2024-01-01 05:59:59',\n",
       "               '2024-01-01 06:59:59', '2024-01-01 07:59:59',\n",
       "               '2024-01-01 08:59:59', '2024-01-01 09:59:59',\n",
       "               ...\n",
       "               '2024-12-31 14:59:59', '2024-12-31 15:59:59',\n",
       "               '2024-12-31 16:59:59', '2024-12-31 17:59:59',\n",
       "               '2024-12-31 18:59:59', '2024-12-31 19:59:59',\n",
       "               '2024-12-31 20:59:59', '2024-12-31 21:59:59',\n",
       "               '2024-12-31 22:59:59', '2024-12-31 23:59:59'],\n",
       "              dtype='datetime64[ns]', name='timestamp', length=8771, freq=None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dfs[0][1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 20.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 27.00it/s]\n",
      "0it [00:00, ?it/s]/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 20.73it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 30.05it/s]\n",
      "0it [00:00, ?it/s]/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 26.62it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 33.49it/s]\n",
      "0it [00:00, ?it/s]/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 25.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 33.17it/s]\n",
      "0it [00:00, ?it/s]/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 26.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 34.88it/s]\n",
      "0it [00:00, ?it/s]/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 26.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 32.14it/s]\n",
      "0it [00:00, ?it/s]/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00, 22.16it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 26.76it/s]\n",
      "0it [00:00, ?it/s]/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "/home/nick/transportation/venv/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:1412: RuntimeWarning: divide by zero encountered in log\n",
      "  aic = self.nobs * np.log(sse / self.nobs) + k * 2\n",
      "/home/nick/transportation/venv/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:1419: RuntimeWarning: divide by zero encountered in log\n",
      "  bic = self.nobs * np.log(sse / self.nobs) + k * np.log(self.nobs)\n",
      "/home/nick/transportation/venv/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:1412: RuntimeWarning: divide by zero encountered in log\n",
      "  aic = self.nobs * np.log(sse / self.nobs) + k * 2\n",
      "/home/nick/transportation/venv/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:1419: RuntimeWarning: divide by zero encountered in log\n",
      "  bic = self.nobs * np.log(sse / self.nobs) + k * np.log(self.nobs)\n",
      "1it [00:00, 48.01it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 41.65it/s]\n",
      "0it [00:00, ?it/s]/2 [00:00<?, ?it/s]\n",
      "1it [00:00, 23.51it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 26.28it/s]\n",
      "0it [00:00, ?it/s]/2 [00:00<?, ?it/s]\n",
      "1it [00:00, 19.43it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 21.46it/s]\n"
     ]
    }
   ],
   "source": [
    "def predict(df):\n",
    "    for col in tqdm(df.columns):\n",
    "        data = df[col].to_frame().sort_index()\n",
    "        data['is_nan'] = data[col].isna().astype(int)\n",
    "        data['group'] = (data['is_nan'].diff() == 1).cumsum()\n",
    "        data = data.reset_index()\n",
    "        nan_intervals = data[data['is_nan'] == 1].groupby(\n",
    "            'group').agg(start=('timestamp', 'first'), end=('timestamp', 'last'))\n",
    "        data = data.set_index('timestamp')\n",
    "        data = data.drop(['is_nan', 'group'], axis=1)\n",
    "        nan_intervals['duration'] = nan_intervals['end'] - nan_intervals['start']\n",
    "        for interval in tqdm(nan_intervals.itertuples()):\n",
    "            if (len(interval) == 0):\n",
    "                continue\n",
    "            start, end, duration = interval.start, interval.end, interval.duration\n",
    "            train_end = data[:start].index[-2]\n",
    "            train_start = (\n",
    "                train_end - pd.Timedelta(days=train_end.weekday())).normalize()\n",
    "            train_start = data.iloc[data.index.get_indexer(\n",
    "                [train_start], method='nearest')[0]].name\n",
    "            train = data[train_start:train_end]\n",
    "            seasonal_periods = 24\n",
    "            if len(train) < seasonal_periods * 2:\n",
    "                train = pd.concat(\n",
    "                    [train, data[:train_start][len(train) - (seasonal_periods*2+1):-1]]).sort_index()\n",
    "                fit = ExponentialSmoothing(\n",
    "                    train.values,\n",
    "                    trend=None,\n",
    "                    seasonal='add',\n",
    "                    seasonal_periods=seasonal_periods,\n",
    "                    damped_trend=False,\n",
    "                ).fit()\n",
    "                predict_index = data.index[data.index.get_loc(\n",
    "                    start):data.index.get_loc(end) + 2]\n",
    "                nan_counts = len(data[start:end])\n",
    "                df.loc[predict_index,f'{col} - predict'] = fit.forecast(int(nan_counts + 1))\n",
    "\n",
    "for name, df in data_dfs:\n",
    "    predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общая интенсивность автомобилей\n",
      "Легковые (до 6 м)\n",
      "Малые груз. (6-9 м)\n",
      "Грузовые (9-13 м)\n",
      "Груз. большие (13-22 м)\n",
      "Автопоезда (22-30 м)\n",
      "Автобусы\n",
      "Мотоциклы\n",
      "Скорость, км/ч\n",
      "Загрузка, %\n"
     ]
    }
   ],
   "source": [
    "for name, df in data_dfs:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulted_df = pd.DataFrame(index=data_dfs[0][1].index)\n",
    "for name, df in data_dfs:\n",
    "    resulted_df = pd.concat([resulted_df, df], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_row = [np.nan]\n",
    "for col_name, cols in zip(list(data_groups.keys())[1:], list(data_groups.values())[1:]):\n",
    "    info_row += (([col_name] * (len(cols) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, (8771, 38))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info_row), resulted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54316/4257859202.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  resulted_df.loc[-1] = info_row\n"
     ]
    }
   ],
   "source": [
    "resulted_df = resulted_df.reset_index()\n",
    "resulted_df.loc[-1] = info_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulted_df.index = resulted_df.index + 1\n",
    "resulted_df = resulted_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/output/км_32+000_а-д_А-146_Краснодар-Верхнебаканский___24-03-2025__01-31-45.xslx'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = str(f'{pathlib.Path(path).parent}/output/{title.replace(\"/\", \"-\").replace(\" \", \"_\")}__{datetime.datetime.now().strftime(\"%d-%m-%Y__%H-%M-%S\")}.xslx')\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(path, mode='a') as writer:\n",
    "    resulted_df.to_excel(excel_writer=writer, sheet_name='predict')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
