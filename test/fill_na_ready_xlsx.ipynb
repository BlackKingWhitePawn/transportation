{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import datetime\n",
    "import dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../samples/report1.xlsx'\n",
    "initial_df = pd.read_excel(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riabt\\AppData\\Local\\Temp\\ipykernel_21076\\1223391092.py:1: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  first_value_index = pd.to_datetime(initial_df.iloc[:, 0], 'coerce', dayfirst=True, infer_datetime_format=True).first_valid_index()\n",
      "C:\\Users\\riabt\\AppData\\Local\\Temp\\ipykernel_21076\\1223391092.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  first_value_index = pd.to_datetime(initial_df.iloc[:, 0], 'coerce', dayfirst=True, infer_datetime_format=True).first_valid_index()\n"
     ]
    }
   ],
   "source": [
    "first_value_index = pd.to_datetime(initial_df.iloc[:, 0], 'coerce', dayfirst=True, infer_datetime_format=True).first_valid_index() \n",
    "df = initial_df.copy()[first_value_index:]\n",
    "df.index = pd.to_datetime(df.index, 'coerce', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 1     NaN\n",
       "Unnamed: 2     NaN\n",
       "Unnamed: 3     NaN\n",
       "Unnamed: 4     NaN\n",
       "Unnamed: 5     NaN\n",
       "Unnamed: 6     NaN\n",
       "Unnamed: 7     NaN\n",
       "Unnamed: 8     NaN\n",
       "Unnamed: 9     NaN\n",
       "Unnamed: 10    NaN\n",
       "Unnamed: 11    NaN\n",
       "Unnamed: 12    NaN\n",
       "Unnamed: 13    NaN\n",
       "Unnamed: 14    NaN\n",
       "Unnamed: 15    NaN\n",
       "Unnamed: 16    NaN\n",
       "Unnamed: 17    NaN\n",
       "Unnamed: 18    NaN\n",
       "Unnamed: 19    NaN\n",
       "Unnamed: 20    NaN\n",
       "Unnamed: 21    NaN\n",
       "Unnamed: 22    NaN\n",
       "Unnamed: 23    NaN\n",
       "Unnamed: 24    NaN\n",
       "Unnamed: 25    NaN\n",
       "Unnamed: 26    NaN\n",
       "Unnamed: 27    NaN\n",
       "Unnamed: 28    NaN\n",
       "Name: 2024-05-25 14:00:01, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broken = '2024-05-25 11:59:59'\n",
    "df.iloc[df.index.get_loc(broken) + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riabt\\AppData\\Local\\Temp\\ipykernel_21076\\1644362668.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  first_value_index = pd.to_datetime(initial_df.iloc[:, 0], 'coerce', dayfirst=True).first_valid_index()\n",
      "10it [00:00, 1111.07it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_data(initial_df):\n",
    "    first_value_index = pd.to_datetime(initial_df.iloc[:, 0], 'coerce', dayfirst=True).first_valid_index() \n",
    "    df = initial_df[first_value_index:]\n",
    "    df.index = pd.to_datetime(df.index, 'coerce', dayfirst=True)\n",
    "    df = df.sort_index()\n",
    "    data_groups = {}\n",
    "    current_group = initial_df.iloc[0].values[0]\n",
    "\n",
    "    for index, value in zip(initial_df.iloc[0].index, initial_df.iloc[0].values):\n",
    "        if (pd.isna(value)):\n",
    "            data_groups[current_group].append(index)\n",
    "        else:\n",
    "            current_group = value\n",
    "            data_groups[current_group] = [index]\n",
    "\n",
    "    data_dfs = []\n",
    "\n",
    "    for group, cols in tqdm(zip(list(data_groups.keys()), list(data_groups.values()))):\n",
    "        data_df = df[cols].copy()\n",
    "        data_df.columns = initial_df[cols].iloc[1].values\n",
    "        data_df.index.names = ['timestamp']\n",
    "        data_dfs.append((group, data_df))\n",
    "\n",
    "    return data_groups, data_dfs\n",
    "\n",
    "data_groups,data_dfs = load_data(initial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken = '2024-05-25 11:59:59'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Итого       NaN\n",
       "Прямое      NaN\n",
       "Обратное    NaN\n",
       "Name: 2024-05-25 13:00:00, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[df.index.get_loc(broken)  + 3]\n",
    "data_dfs[0][1].iloc[data_dfs[0][1].index.get_loc(broken) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Итого</th>\n",
       "      <th>Прямое</th>\n",
       "      <th>Обратное</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-01 00:59:59</th>\n",
       "      <td>367</td>\n",
       "      <td>178</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01 01:59:59</th>\n",
       "      <td>273</td>\n",
       "      <td>125</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01 02:59:59</th>\n",
       "      <td>217</td>\n",
       "      <td>106</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01 03:59:59</th>\n",
       "      <td>190</td>\n",
       "      <td>86</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01 04:59:59</th>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-31 22:59:59</th>\n",
       "      <td>678</td>\n",
       "      <td>362</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-31 23:59:59</th>\n",
       "      <td>478</td>\n",
       "      <td>246</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>12110842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>1183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10259 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Итого Прямое Обратное\n",
       "timestamp                                    \n",
       "2023-12-01 00:59:59       367    178      189\n",
       "2023-12-01 01:59:59       273    125      148\n",
       "2023-12-01 02:59:59       217    106      111\n",
       "2023-12-01 03:59:59       190     86      104\n",
       "2023-12-01 04:59:59       242    118      124\n",
       "...                       ...    ...      ...\n",
       "2025-01-31 22:59:59       678    362      316\n",
       "2025-01-31 23:59:59       478    246      232\n",
       "NaT                  12110842    NaN      NaN\n",
       "NaT                      1183    NaN      NaN\n",
       "NaT                       NaN    NaN      NaN\n",
       "\n",
       "[10259 rows x 3 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dfs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_dfs[0][1]['Итого'].astype(float)\n",
    "\n",
    "# start = pd.Timestamp('2024-06-01 22:00:00')\n",
    "# end = pd.Timestamp('2024-06-01 22:00:00')\n",
    "\n",
    "# i_before = data.index.get_indexer([start]) - 1\n",
    "# i_after = data.index.get_indexer([end]) + 1\n",
    "\n",
    "# data.iloc[i_before] = np.nan\n",
    "# data.iloc[i_after] = np.nan\n",
    "\n",
    "# interpolation = data[start - pd.Timedelta(hours=12):end + pd.Timedelta(hours=12)\n",
    "#      ].interpolate(method='spline', order=2)\n",
    "\n",
    "# prediction_index =  data.index[i_before[0]:i_after[0] + 1]\n",
    "# data_dfs[0][1][prediction_index, 'predict'] = interpolation[prediction_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[start - pd.Timedelta(hours=12):end + pd.Timedelta(hours=12)].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dfs[0][1]['Итого'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp\n",
      "2024-05-25 11:59:59   NaN\n",
      "2024-05-25 13:00:00   NaN\n",
      "2024-05-25 14:00:01   NaN\n",
      "2024-05-25 14:59:59   NaN\n",
      "Name: Общая интенсивность автомобилей - Итого: predict, dtype: float64\n",
      "timestamp\n",
      "2024-06-01 20:59:59   NaN\n",
      "2024-06-01 22:00:00   NaN\n",
      "2024-06-01 22:59:59   NaN\n",
      "Name: Общая интенсивность автомобилей - Итого: predict, dtype: float64\n",
      "timestamp\n",
      "2024-06-03 10:59:59   NaN\n",
      "2024-06-03 12:00:00   NaN\n",
      "2024-06-03 13:00:01   NaN\n",
      "2024-06-03 13:59:59   NaN\n",
      "Name: Общая интенсивность автомобилей - Итого: predict, dtype: float64\n",
      "timestamp\n",
      "2024-06-09 15:59:59   NaN\n",
      "2024-06-09 17:00:00   NaN\n",
      "2024-06-09 18:00:01   NaN\n",
      "2024-06-09 18:59:59   NaN\n",
      "Name: Общая интенсивность автомобилей - Итого: predict, dtype: float64\n",
      "timestamp\n",
      "2024-06-15 15:59:59   NaN\n",
      "2024-06-15 17:00:00   NaN\n",
      "2024-06-15 17:59:59   NaN\n",
      "Name: Общая интенсивность автомобилей - Итого: predict, dtype: float64\n",
      "timestamp\n",
      "2024-07-19 11:59:59   NaN\n",
      "2024-07-19 13:00:00   NaN\n",
      "2024-07-19 13:59:59   NaN\n",
      "Name: Общая интенсивность автомобилей - Итого: predict, dtype: float64\n",
      "timestamp\n",
      "2024-07-20 15:59:59   NaN\n",
      "2024-07-20 17:00:00   NaN\n",
      "2024-07-20 18:00:01   NaN\n",
      "2024-07-20 19:00:02   NaN\n",
      "2024-07-20 19:59:59   NaN\n",
      "Name: Общая интенсивность автомобилей - Итого: predict, dtype: float64\n",
      "timestamp\n",
      "2024-08-21 09:59:59   NaN\n",
      "2024-08-21 11:00:00   NaN\n",
      "2024-08-21 11:59:59   NaN\n",
      "Name: Общая интенсивность автомобилей - Итого: predict, dtype: float64\n",
      "timestamp\n",
      "2024-12-14 15:59:59   NaN\n",
      "2024-12-14 17:00:00   NaN\n",
      "2024-12-14 18:00:01   NaN\n",
      "2024-12-14 19:00:02   NaN\n",
      "2024-12-14 19:59:59   NaN\n",
      "Name: Общая интенсивность автомобилей - Итого: predict, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\PycharmProjects\\transportation\\venv\\lib\\site-packages\\pandas\\core\\missing.py:604: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  terp = interpolate.UnivariateSpline(x, y, k=order, **kwargs)\n",
      "d:\\projects\\PycharmProjects\\transportation\\venv\\lib\\site-packages\\pandas\\core\\missing.py:604: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  terp = interpolate.UnivariateSpline(x, y, k=order, **kwargs)\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m resulted_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mdata_dfs[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mindex)\n\u001b[0;32m     67\u001b[0m \u001b[39mfor\u001b[39;00m name, initial_df \u001b[39min\u001b[39;00m data_dfs:\n\u001b[1;32m---> 68\u001b[0m     predicted \u001b[39m=\u001b[39m predict(initial_df, name)\n\u001b[0;32m     69\u001b[0m     resulted_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([resulted_df, predicted], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 40\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(df, title)\u001b[0m\n\u001b[0;32m     37\u001b[0m train_end \u001b[39m=\u001b[39m data[:start]\u001b[39m.\u001b[39mindex[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[0;32m     38\u001b[0m train_start \u001b[39m=\u001b[39m (\n\u001b[0;32m     39\u001b[0m     train_end \u001b[39m-\u001b[39m pd\u001b[39m.\u001b[39mTimedelta(days\u001b[39m=\u001b[39mtrain_end\u001b[39m.\u001b[39mweekday()))\u001b[39m.\u001b[39mnormalize()\n\u001b[1;32m---> 40\u001b[0m train_start \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39miloc[data\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_indexer(\n\u001b[0;32m     41\u001b[0m     [train_start], method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnearest\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39mname\n\u001b[0;32m     42\u001b[0m train \u001b[39m=\u001b[39m data[train_start:train_end]\n\u001b[0;32m     43\u001b[0m seasonal_periods \u001b[39m=\u001b[39m \u001b[39m24\u001b[39m\n",
      "File \u001b[1;32md:\\projects\\PycharmProjects\\transportation\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3885\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidIndexError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3887\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   3888\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "def predict(df, title):\n",
    "    predicted_df = pd.DataFrame(index=df.index)\n",
    "    for col in df.columns:\n",
    "        data = df[col].to_frame().sort_index()\n",
    "        data['is_nan'] = data[col].isna().astype(int)\n",
    "        data['group'] = (data['is_nan'].diff() == 1).cumsum()\n",
    "        data = data.reset_index()\n",
    "        nan_intervals = data[data['is_nan'] == 1].groupby(\n",
    "            'group').agg(start=('timestamp', 'first'), end=('timestamp', 'last'))\n",
    "        data = data.set_index('timestamp')\n",
    "        data = data.drop(['is_nan', 'group'], axis=1)\n",
    "        data = data.astype(float)\n",
    "        nan_intervals['duration'] = nan_intervals['end'] - nan_intervals['start']\n",
    "        if (len(nan_intervals) == 0):\n",
    "            predicted_df[f'{title} - {col} - predict'] = pd.Series(\n",
    "                    index=predicted_df.index)\n",
    "            continue\n",
    "        for interval in nan_intervals.itertuples():\n",
    "            if (len(interval) == 0):\n",
    "                predicted_df[f'{col} - predict'] = pd.Series(\n",
    "                    index=predicted_df.index)\n",
    "                continue\n",
    "            start, end, duration = interval.start, interval.end, interval.duration\n",
    "            \n",
    "            if (duration < pd.Timedelta(hours=5)):\n",
    "                i_before = data.index.get_loc(start) - 1\n",
    "                i_after = data.index.get_loc(end) + 1\n",
    "                data.iloc[i_before] = np.nan\n",
    "                data.iloc[i_after] = np.nan\n",
    "                interpolation = data.iloc[i_before - 12:i_after].interpolate(method='spline', order=2)\n",
    "                # predict_index =  data.index[i_before[0]:i_after[0] + 1]\n",
    "                predict_index = data.index[int(i_before):int(i_after) + 1]\n",
    "                predicted_df[f'{title} - {col}: predict'] = pd.Series(index=data.index)\n",
    "                print(predicted_df[f'{title} - {col}: predict'].loc[predict_index])\n",
    "                # predicted_df[f'{title} - {col}: predict'].loc[predict_index] = interpolation[predict_index]\n",
    "            else:\n",
    "                train_end = data[:start].index[-2]\n",
    "                train_start = (\n",
    "                    train_end - pd.Timedelta(days=train_end.weekday())).normalize()\n",
    "                train_start = data.iloc[data.index.get_indexer(\n",
    "                    [train_start], method='nearest')[0]].name\n",
    "                train = data[train_start:train_end]\n",
    "                seasonal_periods = 24\n",
    "                eps = 10e-05\n",
    "                if len(train) < seasonal_periods * 2:\n",
    "                    train = pd.concat(\n",
    "                        [train, data[:train_start][len(train) - (seasonal_periods*2+1):-1]]).sort_index()\n",
    "                train = np.log(train.replace(0,1) + eps)\n",
    "                fit = ExponentialSmoothing(\n",
    "                    train.values,\n",
    "                    trend=None,\n",
    "                    seasonal='mul',\n",
    "                    seasonal_periods=seasonal_periods,\n",
    "                    damped_trend=False,\n",
    "                ).fit()\n",
    "                predict_index = data.index[data.index.get_loc(\n",
    "                    start-1):data.index.get_loc(end) + 2]\n",
    "                nan_counts = len(data[start:end])\n",
    "                data[train_start:train_end] = data[train_start:train_end] + eps\n",
    "                predicted_df.loc[predict_index,\n",
    "                                     f'{title} - {col}: predict'] = np.exp(fit.forecast(int(nan_counts + 1)))\n",
    "                \n",
    "    return predicted_df\n",
    "\n",
    "\n",
    "resulted_df = pd.DataFrame(index=data_dfs[0][1].index)\n",
    "for name, initial_df in data_dfs:\n",
    "    predicted = predict(initial_df, name)\n",
    "    resulted_df = pd.concat([resulted_df, predicted], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(DatetimeIndex(['2024-05-24 19:59:59', '2024-05-24 20:59:59',\n               '2024-05-24 21:59:59', '2024-05-24 22:59:59'],\n              dtype='datetime64[ns]', freq=None), 'new')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\projects\\PycharmProjects\\transportation\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:173\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(DatetimeIndex(['2024-05-24 19:59:59', '2024-05-24 20:59:59',\n               '2024-05-24 21:59:59', '2024-05-24 22:59:59'],\n              dtype='datetime64[ns]', freq=None), 'new')' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_dfs[\u001b[39m0\u001b[39;49m][\u001b[39m1\u001b[39;49m][pd\u001b[39m.\u001b[39;49mto_datetime([\u001b[39m'\u001b[39;49m\u001b[39m2024-05-24 19:59:59\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m2024-05-24 20:59:59\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39m2024-05-24 21:59:59\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m2024-05-24 22:59:59\u001b[39;49m\u001b[39m'\u001b[39;49m]), \u001b[39m'\u001b[39;49m\u001b[39mnew\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[1;32md:\\projects\\PycharmProjects\\transportation\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\projects\\PycharmProjects\\transportation\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3817\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3817\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3818\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects\\PycharmProjects\\transportation\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6059\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   6055\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   6056\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   6057\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   6058\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 6059\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (DatetimeIndex(['2024-05-24 19:59:59', '2024-05-24 20:59:59',\n               '2024-05-24 21:59:59', '2024-05-24 22:59:59'],\n              dtype='datetime64[ns]', freq=None), 'new')"
     ]
    }
   ],
   "source": [
    "data_dfs[0][1][pd.to_datetime(['2024-05-24 19:59:59', '2024-05-24 20:59:59','2024-05-24 21:59:59', '2024-05-24 22:59:59']), 'new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2024-01-01 00:59:59     65.0001\n",
       "2024-01-01 01:59:59    134.0001\n",
       "2024-01-01 02:59:59    106.0001\n",
       "2024-01-01 03:59:59     73.0001\n",
       "2024-01-01 04:59:59     42.0001\n",
       "                         ...   \n",
       "2024-12-31 19:59:59    284.0001\n",
       "2024-12-31 20:59:59    212.0001\n",
       "2024-12-31 21:59:59    186.0001\n",
       "2024-12-31 22:59:59    130.0001\n",
       "2024-12-31 23:59:59     47.0001\n",
       "Name: Обратное, Length: 8771, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dfs[0][1]['Обратное'] + 10e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общая интенсивность автомобилей\n",
      "Легковые (до 6 м)\n",
      "Малые груз. (6-9 м)\n",
      "Грузовые (9-13 м)\n",
      "Груз. большие (13-22 м)\n",
      "Автопоезда (22-30 м)\n",
      "Автобусы\n",
      "Мотоциклы\n",
      "Скорость, км/ч\n",
      "Загрузка, %\n"
     ]
    }
   ],
   "source": [
    "for name, initial_df in data_dfs:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = pd.DataFrame(index=data_dfs[0][1].index)\n",
    "# resulted_df['Общая интенсивность автомобилей - Итого: predict'][~resulted_df['Общая интенсивность автомобилей - Итого: predict'].isna()]\n",
    "# for name, df in data_dfs:\n",
    "#     resulted_df = pd.concat([resulted_df, df], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_row = [np.nan]\n",
    "for col_name, cols in zip(list(data_groups.keys())[1:], list(data_groups.values())[1:]):\n",
    "    info_row += [col_name] * len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(nan, 'Общая интенсивность автомобилей - Итого - predict'),\n",
       " ('Общая интенсивность автомобилей',\n",
       "  'Общая интенсивность автомобилей - Прямое - predict'),\n",
       " ('Общая интенсивность автомобилей',\n",
       "  'Общая интенсивность автомобилей - Обратное: predict'),\n",
       " ('Общая интенсивность автомобилей', 'Легковые (до 6 м) - Итого - predict'),\n",
       " ('Легковые (до 6 м)', 'Легковые (до 6 м) - Прямое - predict'),\n",
       " ('Легковые (до 6 м)', 'Легковые (до 6 м) - Обратное: predict'),\n",
       " ('Легковые (до 6 м)', 'Малые груз. (6-9 м) - Итого - predict'),\n",
       " ('Малые груз. (6-9 м)', 'Малые груз. (6-9 м) - Прямое - predict'),\n",
       " ('Малые груз. (6-9 м)', 'Малые груз. (6-9 м) - Обратное: predict'),\n",
       " ('Малые груз. (6-9 м)', 'Грузовые (9-13 м) - Итого - predict'),\n",
       " ('Грузовые (9-13 м)', 'Грузовые (9-13 м) - Прямое - predict'),\n",
       " ('Грузовые (9-13 м)', 'Грузовые (9-13 м) - Обратное: predict'),\n",
       " ('Грузовые (9-13 м)', 'Груз. большие (13-22 м) - Итого - predict'),\n",
       " ('Груз. большие (13-22 м)', 'Груз. большие (13-22 м) - Прямое - predict'),\n",
       " ('Груз. большие (13-22 м)', 'Груз. большие (13-22 м) - Обратное: predict'),\n",
       " ('Груз. большие (13-22 м)', 'Автопоезда (22-30 м) - Итого - predict'),\n",
       " ('Автопоезда (22-30 м)', 'Автопоезда (22-30 м) - Прямое - predict'),\n",
       " ('Автопоезда (22-30 м)', 'Автопоезда (22-30 м) - Обратное: predict'),\n",
       " ('Автопоезда (22-30 м)', 'Автобусы - Итого - predict'),\n",
       " ('Автобусы', 'Автобусы - Прямое - predict'),\n",
       " ('Автобусы', 'Автобусы - Обратное: predict'),\n",
       " ('Автобусы', 'Мотоциклы - Итого - predict'),\n",
       " ('Мотоциклы', 'Мотоциклы - Прямое - predict'),\n",
       " ('Мотоциклы', 'Мотоциклы - Обратное: predict'),\n",
       " ('Мотоциклы', 'Скорость, км/ч - Прямое - predict'),\n",
       " ('Скорость, км/ч', 'Скорость, км/ч - Обратное: predict'),\n",
       " ('Скорость, км/ч', 'Загрузка, % - Прямое - predict'),\n",
       " ('Загрузка, %', 'Загрузка, % - Обратное: predict')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(info_row, resulted_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, (8771, 28))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info_row), resulted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riabt\\AppData\\Local\\Temp\\ipykernel_24540\\4257859202.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  resulted_df.loc[-1] = info_row\n"
     ]
    }
   ],
   "source": [
    "resulted_df = resulted_df.reset_index()\n",
    "resulted_df.loc[-1] = info_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulted_df.index = resulted_df.index + 1\n",
    "resulted_df = resulted_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\samples/output/км_32+000_а-д_А-146_Краснодар-Верхнебаканский___31-03-2025__00-51-51.xslx'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = str(f'{pathlib.Path(path).parent}/output/{title.replace(\"/\", \"-\").replace(\" \", \"_\")}__{datetime.datetime.now().strftime(\"%d-%m-%Y__%H-%M-%S\")}.xslx')\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[147], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m initial_df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'initial_df' is not defined"
     ]
    }
   ],
   "source": [
    "initial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(path,  engine='xlsxwriter') as writer:\n",
    "    # исходные данные\n",
    "    initial_df.to_excel(excel_writer=writer, \n",
    "                         sheet_name='Исходные данные', index=False)\n",
    "    # предсказанные данные\n",
    "    resulted_df = resulted_df.reset_index().rename(columns={'timestamp': 'Дата'})\n",
    "    if 'level_0' in resulted_df.columns:\n",
    "        resulted_df.drop('level_0', axis=1, inplace=True)\n",
    "    if 'index' in resulted_df.columns:\n",
    "        resulted_df.drop('index', axis=1, inplace=True)\n",
    "    resulted_df['Дата'] = resulted_df['Дата'].astype(str)\n",
    "    resulted_df.to_excel(excel_writer=writer, \n",
    "                         sheet_name='Результаты', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
